# Database
DATABASE_URL="sqlite:///./cortex.db"
# For PostgreSQL
# DATABASE_URL="postgresql://postgres:postgres@localhost:5432/cortex"

# Redis
REDIS_HOST="localhost"
REDIS_PORT=6379
# REDIS_PASSWORD=""
REDIS_TTL=3600

# Security
SECURITY_JWT_SECRET="default-jwt-secret-change-me"
SECURITY_ENCRYPTION_KEY="default-encryption-key-change-me"
# 24 hours
SECURITY_TOKEN_EXPIRY_SECONDS=86400

# Server
SERVER_PORT=4000
SERVER_HOST="localhost"
# debug, info, warning, error
SERVER_LOG_LEVEL="info"

# Memory
# whiteboard, jake
MEMORY_TYPE="whiteboard"
MEMORY_RETENTION_DAYS=90
MEMORY_MAX_ITEMS=10000

# MSAL (Microsoft Authentication)
# MSAL_CLIENT_ID=""
# MSAL_CLIENT_SECRET=""
# MSAL_AUTHORITY="https://login.microsoftonline.com/common"

# MCP (Model Context Protocol)
# Format for individual endpoints: MCP_ENDPOINT_NAME=endpoint_url|type
# Example: MCP_ENDPOINT_VSCODE=http://localhost:5000|vscode
# Or use JSON: MCP_ENDPOINTS=[{"name":"vscode","endpoint":"http://localhost:5000","type":"vscode"}]

# Logging
LOG_DIR="logs"
LOG_LEVEL="INFO"
# Enable debug log files that get cleared on each run
DEBUG_LOG_ENABLED=true
DEBUG_MAIN_LOG_PATH="logs/cortex.log.debug_current"
DEBUG_ERROR_LOG_PATH="logs/cortex-error.log.debug_current"
DEBUG_REQUESTS_LOG_PATH="logs/cortex-requests.log.debug_current"

# SSE Configuration
SSE_MAX_CONNECTIONS_PER_CLIENT=5
SSE_HEARTBEAT_INTERVAL=30
SSE_DEBUG=true

# LLM Configuration
LLM_DEFAULT_MODEL="openai/gpt-3.5-turbo"
# Set to true to use mock mode (no actual API calls)
LLM_USE_MOCK=false
# Timeout in seconds for LLM API calls
LLM_TIMEOUT=60

# LLM Provider API Keys
# Choose the ones you need based on which providers you're using
# OPENAI_API_KEY="your-openai-api-key"
# ANTHROPIC_API_KEY="your-anthropic-api-key"
# GOOGLE_API_KEY="your-google-api-key"
# AZURE_API_KEY="your-azure-api-key"
